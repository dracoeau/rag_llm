{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df0d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c30b6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15284b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b2274",
   "metadata": {},
   "source": [
    "## Create LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5796b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a6bac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why don’t skeletons fight each other?\\n\\nThey don’t have the guts!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 10, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BJROUXnrKnSiWc7Y5W1OAWkv8A1XZ', 'finish_reason': 'stop', 'logprobs': None}, id='run-356e13fd-5a33-4f4d-9c19-99362e374dd0-0', usage_metadata={'input_tokens': 10, 'output_tokens': 17, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"tell a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b118dfc",
   "metadata": {},
   "source": [
    "## Process PDF Document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af2fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"./wwf_report.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55b28ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42389733",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500,\n",
    "                                      chunk_overlap=200,\n",
    "                                      length_function=len,\n",
    "                                      separators=[\"\\n\\n\", \"\\n\", \" \"])\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b324d9",
   "metadata": {},
   "source": [
    "## Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3853d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdb8bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, chunk):\n",
    "    return model.embed_query(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fea8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = load_evaluator(evaluator=\"embedding_distance\",\n",
    "                           embeddings=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c81054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.21930473337633283}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_strings(prediction=\"nature\", reference=\"lmao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49848a2f",
   "metadata": {},
   "source": [
    "## Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843fe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8092\\1914020582.py:4: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# vectorstore = Chroma.from_documents(documents=chunks,\n",
    "#                                     embedding=embedding_model,\n",
    "#                                     persist_directory=\"vectorstore\")\n",
    "# vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca9796bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(persist_directory=\"vectorstore\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a3bd7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e27a73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_embedding(embedding_retriever, query):\n",
    "    return embedding_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c3b07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering task.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answe, say that you don't know. DON'T MAKE UP ANYTHING.\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer : the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a4d41a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an assistant for question-answering task.\n",
      "Use the following pieces of retrieved context to answer the question.\n",
      "If you don't know the answe, say that you don't know. DON'T MAKE UP ANYTHING.\n",
      "\n",
      "WWF LIVING PLANET REPORT 2024\n",
      "13 EXECUTIVE SUMMARY\n",
      "Making it happen\n",
      "With every issue of the WWF Living Planet Report, we see a further decline in the state of nature and a \n",
      "destabilization of the climate. This cannot continue.\n",
      "It is no exaggeration to say that what happens in the next five years will determine the future of life on Earth. \n",
      "We have five years to place the world on a sustainable trajectory before negative feedbacks of combined \n",
      "nature degradation and climate change place us on the downhill slope of runaway tipping points. The risk  \n",
      "of failure is real – and the consequences almost unthinkable.\n",
      "As a global community, we have agreed on a way forward. The global goals show where we want to be and \n",
      "the path we need to take. All of us – governments, companies, organizations, individuals – need to walk the \n",
      "walk, and be ready to hold to account those who fail to do so. \n",
      "Together, we must be successful. We have just one living planet, and one opportunity to get it right.\n",
      " \n",
      "EXECUTIVE SUMMARYWWF LIVING PLANET REPORT 2024\n",
      "13\n",
      "It is no exaggeration \n",
      "to say that what \n",
      "happens in the next  \n",
      "five years will \n",
      "determine the future \n",
      "of life on Earth.\n",
      "\n",
      "---\n",
      "\n",
      "WWF LIVING PLANET REPORT 2024\n",
      "3\n",
      " \n",
      "CONTENTS \n",
      "Executive summary   \n",
      "Foreword by Kirsten Schuijt  \n",
      "Foreword by María Susana Muhamad González\n",
      "1. Measuring nature’s decline  \n",
      "         What is biodiversity and why is it important?  \n",
      "         How do we measure nature?  \n",
      " •  Nature narratives: using indicators to understand    \n",
      "change over different timescales  \n",
      " •  Nature narratives: from populations to  \n",
      "ecosystem function\n",
      "         The global Living Planet Index 2024\n",
      "         Understanding drivers of change to nature through  \n",
      "             regional perspectives  \n",
      "         Case studies  \n",
      "2. Tipping points\n",
      "         Early warning signals  \n",
      " •  North America: fire suppression, drought  \n",
      "and invasive species \n",
      " •  Great Barrier Reef: overfishing, pollution and  \n",
      "warming waters  \n",
      " •   India: wetland loss, drought and flooding  \n",
      "         Tipping points with global significance  \n",
      "         A wake-up call \n",
      "3. Global goals and progress\n",
      "          Reaching 2030 on the pathway to a  \n",
      "sustainable future \n",
      "4. Sustainable solutions  \n",
      "         Nature conservation  \n",
      " •  Evolving approaches to conservation  \n",
      " •  Transforming conservation\n",
      "         The food system  \n",
      " •  Challenges with the current food system  \n",
      " •  Food system transformation: what’s needed?  \n",
      "         The energy system  \n",
      " •  Challenges with the current energy system  \n",
      " •  Energy transformation: what’s needed?  \n",
      " •  How do we achieve a transformation that is  \n",
      "faster, greener and fairer? \n",
      "         Green finance  \n",
      " •  Financing green\n",
      "\n",
      "---\n",
      "\n",
      "WWF LIVING PLANET REPORT 2024\n",
      "1\n",
      "A System in PerilA System in Peril\n",
      "2024LIVINGPLANETREPORT\n",
      "A System in Peril\n",
      "\n",
      "---\n",
      "\n",
      "WWF LIVING PLANET REPORT 2024\n",
      "6\n",
      "EXECUTIVE \n",
      "SUMMARY\n",
      "When cumulative \n",
      "impacts reach a \n",
      "threshold, the  \n",
      "change becomes  \n",
      "self-perpetuating, \n",
      "resulting in substantial, \n",
      "often abrupt and \n",
      "potentially irreversible \n",
      "change – a tipping \n",
      "point.\n",
      "\n",
      "---\n",
      "\n",
      "Answer : the question based on the above context: Give a summary of the report\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Give a summary of the report\"\n",
    "relevant_chunks = query_embedding(retriever, query)\n",
    "\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in relevant_chunks])\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "prompt = prompt_template.format(context=context_text,\n",
    "                                question=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a73c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bf5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25493f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e5ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68167758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
